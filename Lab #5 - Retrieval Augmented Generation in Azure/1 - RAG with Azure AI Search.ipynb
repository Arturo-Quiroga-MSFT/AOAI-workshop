{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Cognitive Search Vector Search Code Sample with Azure OpenAI\n",
    "This code demonstrates how to use Azure Cognitive Search with OpenAI and Azure Python SDK\n",
    "\n",
    "Author: [Vlad Feigin - Cloud Solution Architect - Microsoft](<https://www.linkedin.com/in/vladifeigin/>)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-search-documents in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (11.6.0b2)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.28.0 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-search-documents) (1.29.4)\n",
      "Requirement already satisfied: azure-common~=1.1 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-search-documents) (1.1.28)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-search-documents) (0.6.1)\n",
      "Requirement already satisfied: requests>=2.18.4 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-core<2.0.0,>=1.28.0->azure-search-documents) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\raalvar\\appdata\\roaming\\python\\python312\\site-packages (from azure-core<2.0.0,>=1.28.0->azure-search-documents) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-core<2.0.0,>=1.28.0->azure-search-documents) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.28.0->azure-search-documents) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.28.0->azure-search-documents) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.28.0->azure-search-documents) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.28.0->azure-search-documents) (2023.7.22)\n",
      "Requirement already satisfied: tenacity in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (8.2.3)\n",
      "Requirement already satisfied: langchain in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.1.12)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.0.28)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.28 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.0.28)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.31 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.1.32)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.1.27)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.6.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.31->langchain) (4.2.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.31->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.9.15)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.16.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.31->langchain) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\raalvar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-4.1.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Downloading pypdf-4.1.0-py3-none-any.whl (286 kB)\n",
      "   ---------------------------------------- 0.0/286.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 286.1/286.1 kB 8.9 MB/s eta 0:00:00\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-4.1.0\n"
     ]
    }
   ],
   "source": [
    "! pip install azure-search-documents --pre --upgrade\n",
    "! pip install tenacity\n",
    "! pip install langchain\n",
    "! pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "# Configure environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SimpleField,\n",
    "    SearchFieldDataType,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    SemanticConfiguration,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    SemanticSearch,\n",
    "    SearchIndex,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(openai_credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "# Configure environment variables\n",
    "service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\")\n",
    "key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_ENDPOINT\")\n",
    "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_MODEL_NAME\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "# Configure OpenAI API\n",
    "client = AzureOpenAI(\n",
    "    azure_deployment=azure_openai_embedding_deployment,\n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    api_key=azure_openai_key,\n",
    "    azure_ad_token_provider=token_provider if not azure_openai_key else None\n",
    ")\n",
    "credential = AzureKeyCredential(key)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings\n",
    "Read your data, generate OpenAI embeddings and export to a format to insert your Azure Cognitive Search index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dschlesinger\\code\\ongoing\\workshops\\AOAI-workshop\\.venv\\lib\\site-packages\\langchain\\embeddings\\azure_openai.py:101: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://aidemos-workshop.openai.azure.com/ to https://aidemos-workshop.openai.azure.com//openai.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dschlesinger\\code\\ongoing\\workshops\\AOAI-workshop\\.venv\\lib\\site-packages\\langchain\\embeddings\\azure_openai.py:108: UserWarning: As of openai>=1.0.0, if `deployment` (or alias `azure_deployment`) is specified then `openai_api_base` (or alias `base_url`) should not be. Instead use `deployment` (or alias `azure_deployment`) and `azure_endpoint`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dschlesinger\\code\\ongoing\\workshops\\AOAI-workshop\\.venv\\lib\\site-packages\\langchain\\embeddings\\azure_openai.py:116: UserWarning: As of openai>=1.0.0, if `openai_api_base` (or alias `base_url`) is specified it is expected to be of the form https://example-resource.azure.openai.com/openai/deployments/example-deployment. Updating https://aidemos-workshop.openai.azure.com/ to https://aidemos-workshop.openai.azure.com//openai.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.009420825504358491, -0.004646901672600355, -0.0015674912696747403]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test embedding with langchain\n",
    "embeddingmodel = AzureOpenAIEmbeddings(\n",
    "    deployment=OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME,\n",
    "    model=OPENAI_ADA_EMBEDDING_MODEL_NAME,\n",
    "    openai_api_base=OPENAI_DEPLOYMENT_ENDPOINT,\n",
    "    chunk_size = 1)\n",
    "\n",
    "vec = embeddingmodel.embed_query(\"transform to vec\")\n",
    "vec[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Document Embeddings using OpenAI Ada 002\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "# Function to generate embeddings for title and content fields, also used for query embeddings\n",
    "def generate_embeddings(text):\n",
    "    embeddings = embeddingmodel.embed_query(text)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for loading into Azure Cognitive Search - DO THIS ONLY ONCE !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages:  187\n"
     ]
    }
   ],
   "source": [
    "doc_title = \"Semantic Kernel\"\n",
    "# load pdf and split into pages\n",
    "fileName = \"./data/semantic-kernel.pdf\"\n",
    "loader = PyPDFLoader(fileName)\n",
    "pages = loader.load_and_split()\n",
    "print(\"Number of pages: \", len(pages))\n",
    "\n",
    "doc_with_vector_list = []\n",
    "doc_id = 0\n",
    "# Generate embeddings for title and content fields\n",
    "for page in pages:\n",
    "    page_with_vector = {}\n",
    "    page_with_vector['id'] = str(doc_id)\n",
    "    page_with_vector['title'] = doc_title\n",
    "    page_with_vector['titleVector'] = client.embeddings.create(input=doc_title, model=azure_openai_embedding_deployment).data[0].embedding\n",
    "    page_with_vector['content'] = page.page_content\n",
    "    page_with_vector['contentVector'] = client.embeddings.create(input=page.page_content, model=azure_openai_embedding_deployment).data[0].embedding\n",
    "    doc_with_vector_list.append(page_with_vector)\n",
    "    doc_id += 1\n",
    "\n",
    "# Output embeddings to docVectors.json file\n",
    "with open(\"./sk_Vectors1.json\", \"w\") as f:\n",
    "    json.dump(doc_with_vector_list, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create search index - DO THIS ONLY ONCE !!!\n",
    "Create your search index schema and vector search configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " rag created\n"
     ]
    }
   ],
   "source": [
    "# Create a search index\n",
    "# Note: You must create Cognitive Search resource and get the endpoint and key in advance\n",
    "index_client = SearchIndexClient(endpoint=service_endpoint, credential=credential)\n",
    "\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchableField(name=\"title\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"category\", type=SearchFieldDataType.String,\n",
    "                    filterable=True),\n",
    "    SearchField(name=\"titleVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\"),\n",
    "    SearchField(name=\"contentVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\"),\n",
    "]\n",
    "\n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(\n",
    "            name=\"myHnsw\"\n",
    "        )\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"myHnswProfile\",\n",
    "            algorithm_configuration_name=\"myHnsw\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"title\"),\n",
    "        keywords_fields=[SemanticField(field_name=\"category\")],\n",
    "        content_fields=[SemanticField(field_name=\"content\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the semantic settings with the configuration\n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name=index_name, fields=fields,\n",
    "                    vector_search=vector_search, semantic_search=semantic_search)\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f' {result.name} created')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert text and embeddings into vector store - DO THIS ONLY ONCE !!\n",
    "Add texts and metadata from the JSON data to the vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 187 documents\n"
     ]
    }
   ],
   "source": [
    "# Upload documents to the index\n",
    "with open('./sk_Vectors1.json', 'r') as file:\n",
    "    documents = json.load(file)\n",
    "search_client = SearchClient(endpoint=service_endpoint, index_name=index_name, credential=credential)\n",
    "result = search_client.upload_documents(documents)\n",
    "print(f\"Uploaded {len(documents)} documents\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a vector similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Semantic Kernel\n",
      "Score: 0.8932474\n",
      "Content: Tell us about y our PDF experience.\n",
      "What is Semantic Kernel?\n",
      "Article •07/11/2023\n",
      "Semantic K ernel is an open-source SDK that lets you easily combine AI services like\n",
      "OpenAI , Azure OpenAI , and Hugging F ace  with conventional programming\n",
      "languages like C# and Python. By doing so, you can create AI apps that combine the\n",
      "best of both worlds.\n",
      "During K evin Scott's talk The era of the AI Copilot , he showed how Microsoft powers its\n",
      "Copilot system  with a stack of AI models and plugins. At the center of this stack is an AI\n",
      "orchestration layer that allows us to combine AI models and plugins together to create\n",
      "brand new experiences for users.\n",
      "Semantic Kernel is at the center of the copilot\n",
      "stack\n",
      "Category: None\n",
      "\n",
      "Title: Semantic Kernel\n",
      "Score: 0.8851806\n",
      "Content: Additional learning for Semantic Kernel\n",
      "Article •07/11/2023\n",
      "Want to learn more about Semantic K ernel? Check out these in-depth tutorials and\n",
      "videos. W e will add more content over time from our team and community, so check\n",
      "back often!\n",
      "Cook with Semantic Kernel\n",
      "Learn how to supercharge your problem-solving creativity with Semantic K ernel running\n",
      "on your own machine just like your own “Easy Bake Oven.” W e’ll use plenty of cooking\n",
      "analogies to land the core ideas of LLM AI running on Semantic K ernel so be prepared\n",
      "to get hungry!\n",
      " \n",
      "Kernel syntax examplesStart the tut orial\n",
      "Category: None\n",
      "\n",
      "Title: Semantic Kernel\n",
      "Score: 0.8844227\n",
      "Content: Visual Code Studio Semantic Kernel\n",
      "Extension\n",
      "Article •05/23/2023\n",
      "The Semantic K ernel T ools help developers to write semantic functions for Semantic\n",
      "Kernel .\n",
      "With the Semantic K ernel T ools, you can easily create new semantic functions and test\n",
      "them without needing to write any code. Behind the scenes, the tools use the Semantic\n",
      "Kernel SDK so you can easily transition from using the tools to integrating your semantic\n",
      "functions into your own code.\n",
      "In the following image you can see how a user can easily view all of their semantic\n",
      "functions, edit them, and run them from within Visual S tudio Code using any of the\n",
      "supported AI endpoints.\n",
      "７ Note\n",
      "Skills are currently being renamed to plugins. This article has been updated to\n",
      "reflect the latest terminology, but some images and code samples may still refer to\n",
      "skills.\n",
      "These tools simplify Semantic Kernel\n",
      "development\n",
      "Category: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.models import VectorizedQuery\n",
    "\n",
    "# Pure Vector Search\n",
    "query = \"what is semantic kernel?\"  \n",
    "  \n",
    "embedding = client.embeddings.create(input=query, model=azure_openai_embedding_deployment).data[0].embedding\n",
    "vector_query = VectorizedQuery(vector=embedding, k_nearest_neighbors=3, fields=\"contentVector\")\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['content']}\")  \n",
    "    print(f\"Category: {result['category']}\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Semantic Kernel\n",
      "Score: 0.87037426\n",
      "Content: To simplify the creation of AI apps, open source projects like LangChain  have\n",
      "emerged. Semantic K ernel is Microsoft's contribution to this space and is designed to\n",
      "support enterprise app developers who want to integrate AI into their existing apps.\n",
      "By using multiple AI models, plugins, and memory all together within Semantic K ernel,\n",
      "you can create sophisticated pipelines that allow AI to automate complex tasks for users.\n",
      "For example, with Semantic K ernel, you could create a pipeline that helps a user send an\n",
      "email to their marketing team. With memory , you could retrieve information about the\n",
      "project and then use planner  to autogenerate the remaining steps using available\n",
      "plugins (e.g., ground the user's ask with Microsoft Graph data, generate a response with\n",
      "GPT-4, and send the email). Finally, you can display a success message back to your user\n",
      "in your app using a custom plugin.\n",
      "Step Component Descr iption\n",
      "1 Ask It starts with a goal being sent to Semantic K ernel by either a user or\n",
      "developer.\n",
      "2 Kernel The kernel  orchestrates a user's ask. T o do so, the kernel runs a pipeline /\n",
      "chain  that is defined by a developer. While the chain is run, a common\n",
      "context is provided by the kernel so data can be shared between functions.\n",
      "2.1 Memories With a specialized plugin, a developer can recall and store context in\n",
      "vector databases. This allows developers to simulate memory  within their\n",
      "AI apps.\n",
      "2.2 Planner Developers can ask Semantic K ernel to auto create chains to address novel\n",
      "needs for a user. Planner  achieves this by mixing-and-matching plugins\n",
      "Seeing AI orchestration with Semantic Kernel\n",
      "Title: Semantic Kernel\n",
      "Score: 0.8700594\n",
      "Content: This article only scratches the surface of what you can do with the kernel. T o learn more\n",
      "about additional features, check out the following articles.\n",
      "Your go al Next st ep\n",
      "Learn what plugins are and what they can do Understand AI plugins\n",
      "Create more advanced pipelines with Semantic K ernel Chaining functions together\n",
      "Automatically creating pipelines with Planner Auto create plans with planner\n",
      "Simulating memory within Semantic K ernel Give you AI memories\n",
      "Under standing plugins\n"
     ]
    }
   ],
   "source": [
    "query = \"semantic kernel planner and kernel\"\n",
    "\n",
    "embedding = client.embeddings.create(input=query, model=azure_openai_embedding_deployment).data[0].embedding\n",
    "vector_query = VectorizedQuery(vector=embedding, k_nearest_neighbors=2, fields=\"contentVector\")\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=None,\n",
    "    vector_queries=[vector_query], \n",
    "    select=[\"title\", \"content\"],\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform an Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Semantic Kernel\n",
      "Score: 0.03306011110544205\n",
      "Content: To simplify the creation of AI apps, open source projects like LangChain  have\n",
      "emerged. Semantic K ernel is Microsoft's contribution to this space and is designed to\n",
      "support enterprise app developers who want to integrate AI into their existing apps.\n",
      "By using multiple AI models, plugins, and memory all together within Semantic K ernel,\n",
      "you can create sophisticated pipelines that allow AI to automate complex tasks for users.\n",
      "For example, with Semantic K ernel, you could create a pipeline that helps a user send an\n",
      "email to their marketing team. With memory , you could retrieve information about the\n",
      "project and then use planner  to autogenerate the remaining steps using available\n",
      "plugins (e.g., ground the user's ask with Microsoft Graph data, generate a response with\n",
      "GPT-4, and send the email). Finally, you can display a success message back to your user\n",
      "in your app using a custom plugin.\n",
      "Step Component Descr iption\n",
      "1 Ask It starts with a goal being sent to Semantic K ernel by either a user or\n",
      "developer.\n",
      "2 Kernel The kernel  orchestrates a user's ask. T o do so, the kernel runs a pipeline /\n",
      "chain  that is defined by a developer. While the chain is run, a common\n",
      "context is provided by the kernel so data can be shared between functions.\n",
      "2.1 Memories With a specialized plugin, a developer can recall and store context in\n",
      "vector databases. This allows developers to simulate memory  within their\n",
      "AI apps.\n",
      "2.2 Planner Developers can ask Semantic K ernel to auto create chains to address novel\n",
      "needs for a user. Planner  achieves this by mixing-and-matching plugins\n",
      "Seeing AI orchestration with Semantic Kernel\n",
      "Category: None\n",
      "\n",
      "Title: Semantic Kernel\n",
      "Score: 0.032258063554763794\n",
      "Content: Responsible AI and Semantic Kernel\n",
      "Article •05/23/2023\n",
      "An AI system includes not only the technology, but also the people who will use it, the\n",
      "people who will be affected by it, and the environment in which it is deployed. Creating\n",
      "a system that is fit for its intended purpose requires an understanding of how the\n",
      "technology works, what its capabilities and limitations are, and how to achieve the best\n",
      "performance. Microsoft’s T ransparency Notes are intended to help you understand how\n",
      "our AI technology works, the choices system owners can make that influence system\n",
      "performance and behavior, and the importance of thinking about the whole system,\n",
      "including the technology, the people, and the environment. Y ou can use T ransparency\n",
      "Notes when developing or deploying your own system, or share them with the people\n",
      "who will use or be affected by your system.\n",
      "Microsoft’s T ransparency Notes are part of a broader effort at Microsoft to put our AI\n",
      "Principles into practice. T o find out more, see the Microsoft AI principles .\n",
      "Semantic K ernel (SK) is a lightweight SDK that lets you easily mix conventional\n",
      "programming languages with the latest in Large Language Model (LLM) AI \"prompts\"\n",
      "with templating, chaining, and planning capabilities out-of-the-box.\n",
      "Semantic K ernel (SK) builds upon the following five concepts:\n",
      "Concept Shor t Descr iption\n",
      "Kernel The kernel orchestrates a user's ASK expressed as a goal\n",
      "Planner Planner breaks it down into steps based upon resources that are available\n",
      "Plugins Plugins are customizable resources built from LLM AI prompts and native codeWhat is a Transparency Note?\n",
      "Introduction to Semantic Kernel\n",
      "The basics of Semantic Kernel\n",
      "Category: None\n",
      "\n",
      "Title: Semantic Kernel\n",
      "Score: 0.03067915514111519\n",
      "Content: This article only scratches the surface of what you can do with the kernel. T o learn more\n",
      "about additional features, check out the following articles.\n",
      "Your go al Next st ep\n",
      "Learn what plugins are and what they can do Understand AI plugins\n",
      "Create more advanced pipelines with Semantic K ernel Chaining functions together\n",
      "Automatically creating pipelines with Planner Auto create plans with planner\n",
      "Simulating memory within Semantic K ernel Give you AI memories\n",
      "Under standing plugins\n",
      "Category: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hybrid Search\n",
    "query = \"semantic kernel planner and kernel\"  \n",
    "  \n",
    "embedding = client.embeddings.create(input=query, model=azure_openai_embedding_deployment).data[0].embedding\n",
    "vector_query = VectorizedQuery(vector=embedding, k_nearest_neighbors=3, fields=\"contentVector\")\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=query,  \n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    "    top=3\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['content']}\")  \n",
    "    print(f\"Category: {result['category']}\\n\")  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a Semantic Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Answer: Semantic Kernel.<em> any other operation that you can do in code that is ill-suited for</em> LLMs<em> (e.g., performing calculations).</em> Instead of providing a separate configuration file with semantic descriptions,<em> planner is able to use annotations in the code to understand how the function behaves.</em>\n",
      "Semantic Answer Score: 0.71630859375\n",
      "\n",
      "Title: Semantic Kernel\n",
      "Reranker Score: 3.5381433963775635\n",
      "Content: To instantiate planner, all you need to do is pass it a kernel object. Planner will then\n",
      "automatically discover all of the plugins registered in the kernel and use them to create\n",
      "plans. The following code initializes both a kernel and a SequentialPlanner. At the end\n",
      "of this article we'll review the other types of Planners that are available in Semantic\n",
      "Kernel.\n",
      "C#      return (\n",
      "          Convert.ToDouble(context[ \"input\"], \n",
      "CultureInfo.InvariantCulture) -\n",
      "          Convert.ToDouble(context[ \"number2\" ], \n",
      "CultureInfo.InvariantCulture)\n",
      "      ).ToString(CultureInfo.InvariantCulture);\n",
      "  }\n",
      "  [SKFunction, Description( \"Multiply two numbers. When increasing by a  \n",
      "percentage, don't forget to add 1 to the percentage.\" )]\n",
      "  [SKParameter( \"input\", \"The first number to multiply\" )]\n",
      "  [SKParameter( \"number2\" , \"The second number to multiply\" )]\n",
      "  public string Multiply (SKContext context )\n",
      "  {\n",
      "      return (\n",
      "          Convert.ToDouble(context[ \"input\"], \n",
      "CultureInfo.InvariantCulture) *\n",
      "          Convert.ToDouble(context[ \"number2\" ], \n",
      "CultureInfo.InvariantCulture)\n",
      "      ).ToString(CultureInfo.InvariantCulture);\n",
      "  }\n",
      "  [SKFunction, Description( \"Divide two numbers\" )]\n",
      "  [SKParameter( \"input\", \"The first number to divide from\" )]\n",
      "  [SKParameter( \"number2\" , \"The second number to divide by\" )]\n",
      "  public string Divide(SKContext context )\n",
      "  {\n",
      "      return (\n",
      "          Convert.ToDouble(context[ \"input\"], \n",
      "CultureInfo.InvariantCulture) /\n",
      "          Convert.ToDouble(context[ \"number2\" ], \n",
      "CultureInfo.InvariantCulture)\n",
      "      ).ToString(CultureInfo.InvariantCulture);\n",
      "  }\n",
      "}\n",
      "Instantiating planner\n",
      "C#\n",
      "Category: None\n",
      "Caption: Semantic Kernel. To instantiate planner, all you need to do is pass it a<em> kernel</em> object. Planner will then automatically discover all of the plugins registered in the kernel and use them to create<em> plans.</em> The following code initializes both a kernel and a SequentialPlanner.\n",
      "\n",
      "Title: Semantic Kernel\n",
      "Reranker Score: 3.129901885986328\n",
      "Content: C#\n",
      "You should get a response like the following. Notice how the response is now more\n",
      "natural sounding.\n",
      "Output\n",
      "You are now becoming familiar with orchestrating both semantic and non-semantic\n",
      "functions. Up until now, however, you've had to manually orchestrate the functions. In\n",
      "the next section, you'll learn how to use planner to orchestrate functions automatically.using Microsoft.SemanticKernel;\n",
      "using Plugins;\n",
      "// ... instantiate your kernel\n",
      "var pluginsDirectory =  \n",
      "Path.Combine(System.IO.Directory.GetCurrentDirectory(), \"plugins\" );\n",
      "// Import the semantic functions\n",
      "kernel.ImportSemanticSkillFromDirectory(pluginsDirectory, \n",
      "\"OrchestratorPlugin\" );\n",
      "kernel.ImportSemanticSkillFromDirectory(pluginsDirectory, \n",
      "\"SummarizeSkill\" );\n",
      "// Import the native functions\n",
      "var mathPlugin = kernel.ImportSkill( new MathPlugin(), \"MathPlugin\" );\n",
      "var orchestratorPlugin = kernel.ImportSkill( new \n",
      "OrchestratorPlugin(kernel), \"OrchestratorPlugin\" );\n",
      "// Make a request that runs the Sqrt function\n",
      "var result1 = await orchestratorPlugin[ \"RouteRequest\" ]\n",
      "    .InvokeAsync( \"What is the square root of 524?\" );\n",
      "Console.WriteLine(result1);\n",
      "// Make a request that runs the Add function\n",
      "var result2 = await orchestratorPlugin[ \"RouteRequest\" ]\n",
      "    .InvokeAsync( \"How many sheep would I have if I started with 3 and  \n",
      "then got 7 more?\" );\n",
      "Console.WriteLine(result2);\n",
      "The square root of 524 is 22.891046284519195.\n",
      "You would have 10 sheep.\n",
      "Take the next step\n",
      "Category: None\n",
      "Caption: in the next section, you'll learn how to use<em> planner</em> to orchestrate<em> functions</em> automatically.using microsoft.semantickernel; using<em> plugins;</em> // ... instantiate your<em> kernel</em> var<em> pluginsdirectory</em> =   path.combine(system.io.directory.getcurrentdirectory(), \"plugins\" ); // import the<em> semantic functions</em> …\n",
      "\n",
      "Title: Semantic Kernel\n",
      "Reranker Score: 3.096200942993164\n",
      "Content: Now that we have planner, we can use it to create a plan for a user's ask and then\n",
      "invoke the plan to get a result. The following code asks our planner to solve a math\n",
      "problem that is difficult for an LLM to solve on its own because it requires multiple steps\n",
      "and it has numbers with decimal points.\n",
      "C#\n",
      "After running this code, you should get the correct answer of 2615.1829 back, but how?\n",
      "Behind the scenes, planner uses an LLM prompt to generate a plan. Y ou can see the\n",
      "prompt that is used by SequentialPlanner by navigating to the skprompt.t xt file  in the\n",
      "Semantic K ernel repository. Y ou can also view the prompt used by the basic planner  in\n",
      "Python.using Microsoft.SemanticKernel;\n",
      "using Plugins;\n",
      "// ... instantiate your kernel\n",
      "// Add the math plugin\n",
      "var mathPlugin = kernel.ImportSkill( new MathPlugin(), \"MathPlugin\" );\n",
      "// Create planner\n",
      "var planner = new SequentialPlanner(kernel);\n",
      "Creating and running a plan\n",
      "C#\n",
      "// Create a plan for the ask\n",
      "var ask = \"If my investment of 2130.23 dollars increased by 23%, how  \n",
      "much would I have after I spent $5 on a latte?\" ;\n",
      "var plan = await planner.CreatePlanAsync(ask);\n",
      "// Execute the plan\n",
      "var result = await plan.InvokeAsync();\n",
      "Console.WriteLine( \"Plan results:\" );\n",
      "Console.WriteLine(result.Result);\n",
      "How does planner work?\n",
      "Category: None\n",
      "Caption: y ou can also view the prompt used by the basic<em> planner</em>  in python.using microsoft.semantickernel; using plugins; // ... instantiate your<em> kernel</em> // add the math plugin var mathplugin = kernel.importskill( new mathplugin(), \"mathplugin\" ); // create<em> planner</em> var<em> planner</em> = new<em> sequentialplanner(kernel);</em> creating and running a<em> plan</em> c# // create a …\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.models import QueryType, QueryCaptionType, QueryAnswerType\n",
    "# Semantic Hybrid Search\n",
    "query = \"semantic kernel planner and kernel\"\n",
    "\n",
    "embedding = client.embeddings.create(input=query, model=azure_openai_embedding_deployment).data[0].embedding\n",
    "vector_query = VectorizedQuery(vector=embedding, k_nearest_neighbors=3, fields=\"contentVector\")\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=query,\n",
    "    vector_queries=[vector_query], \n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    "    query_type=QueryType.SEMANTIC, semantic_configuration_name='my-semantic-config', query_caption=QueryCaptionType.EXTRACTIVE, query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "    top=3\n",
    ")\n",
    "\n",
    "semantic_answers = results.get_answers()\n",
    "for answer in semantic_answers:\n",
    "    if answer.highlights:\n",
    "        print(f\"Semantic Answer: {answer.highlights}\")\n",
    "    else:\n",
    "        print(f\"Semantic Answer: {answer.text}\")\n",
    "    print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Reranker Score: {result['@search.reranker_score']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "    print(f\"Category: {result['category']}\")\n",
    "\n",
    "    captions = result[\"@search.captions\"]\n",
    "    if captions:\n",
    "        caption = captions[0]\n",
    "        if caption.highlights:\n",
    "            print(f\"Caption: {caption.highlights}\\n\")\n",
    "        else:\n",
    "            print(f\"Caption: {caption.text}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
