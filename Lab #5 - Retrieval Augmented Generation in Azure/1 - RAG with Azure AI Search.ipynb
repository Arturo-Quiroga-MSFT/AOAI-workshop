{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Cognitive Search Vector Search Code Sample with Azure OpenAI\n",
    "This code demonstrates how to use Azure Cognitive Search with OpenAI and Azure Python SDK\n",
    "\n",
    "Author: [Vlad Feigin - Cloud Solution Architect - Microsoft](<https://www.linkedin.com/in/vladifeigin/>)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-search-documents in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (11.6.0b2)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.28.0 in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (from azure-search-documents) (1.30.1)\n",
      "Requirement already satisfied: azure-common~=1.1 in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (from azure-search-documents) (1.1.28)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (from azure-search-documents) (0.6.1)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (from azure-core<2.0.0,>=1.28.0->azure-search-documents) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (from azure-core<2.0.0,>=1.28.0->azure-search-documents) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (from azure-core<2.0.0,>=1.28.0->azure-search-documents) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-search-documents) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-search-documents) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-search-documents) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-search-documents) (2024.2.2)\n",
      "Requirement already satisfied: azure-identity in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (1.15.0)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.23.0 in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (from azure-identity) (1.30.1)\n",
      "Requirement already satisfied: cryptography>=2.5 in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (from azure-identity) (42.0.5)\n",
      "Requirement already satisfied: msal<2.0.0,>=1.24.0 in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (from azure-identity) (1.28.0)\n",
      "Requirement already satisfied: msal-extensions<2.0.0,>=0.3.0 in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (from azure-identity) (1.1.0)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (from azure-core<2.0.0,>=1.23.0->azure-identity) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (from azure-core<2.0.0,>=1.23.0->azure-identity) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (from azure-core<2.0.0,>=1.23.0->azure-identity) (4.10.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (from cryptography>=2.5->azure-identity) (1.16.0)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (from PyJWT[crypto]<3,>=1.0.0->msal<2.0.0,>=1.24.0->azure-identity) (2.8.0)\n",
      "Requirement already satisfied: packaging in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity) (23.2)\n",
      "Requirement already satisfied: portalocker<3,>=1.6 in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity) (2.8.2)\n",
      "Requirement already satisfied: pycparser in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity) (2.21)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (from portalocker<3,>=1.6->msal-extensions<2.0.0,>=0.3.0->azure-identity) (306)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.23.0->azure-identity) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.23.0->azure-identity) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.23.0->azure-identity) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\vsprojects\\aoai-workshop\\venv\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.23.0->azure-identity) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install azure-search-documents --pre --upgrade\n",
    "! pip install azure-identity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "# Configure environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SimpleField,\n",
    "    SearchFieldDataType,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    SemanticConfiguration,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    SemanticSearch,\n",
    "    SearchIndex,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(openai_credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "# Configure environment variables\n",
    "service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "index_name = \"mydocs\"\n",
    "key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "\n",
    "azure_openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "azure_openai_endpoint = os.getenv(\"OPENAI_DEPLOYMENT_ENDPOINT\")\n",
    "azure_openai_embedding_deployment = os.getenv(\"OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "azure_openai_api_version = \"2024-02-15-preview\"\n",
    "\n",
    "# Configure OpenAI API\n",
    "client = AzureOpenAI(\n",
    "    azure_deployment=azure_openai_embedding_deployment,\n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    api_key=azure_openai_key,\n",
    "    azure_ad_token_provider=token_provider if not azure_openai_key else None\n",
    ")\n",
    "credential = AzureKeyCredential(key)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings\n",
    "Read your data, generate OpenAI embeddings and export to a format to insert your Azure Cognitive Search index:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for loading into Azure Cognitive Search - DO THIS ONLY ONCE !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages:  187\n"
     ]
    }
   ],
   "source": [
    "doc_title = \"Semantic Kernel\"\n",
    "# load pdf and split into pages\n",
    "fileName = \"./data/semantic-kernel.pdf\"\n",
    "loader = PyPDFLoader(fileName)\n",
    "pages = loader.load_and_split()\n",
    "print(\"Number of pages: \", len(pages))\n",
    "\n",
    "doc_with_vector_list = []\n",
    "doc_id = 0\n",
    "# Generate embeddings for title and content fields\n",
    "for page in pages:\n",
    "    page_with_vector = {}\n",
    "    page_with_vector['id'] = str(doc_id)\n",
    "    page_with_vector['title'] = doc_title\n",
    "    page_with_vector['titleVector'] = client.embeddings.create(input=doc_title, model=azure_openai_embedding_deployment).data[0].embedding\n",
    "    page_with_vector['content'] = page.page_content\n",
    "    page_with_vector['contentVector'] = client.embeddings.create(input=page.page_content, model=azure_openai_embedding_deployment).data[0].embedding\n",
    "    doc_with_vector_list.append(page_with_vector)\n",
    "    doc_id += 1\n",
    "\n",
    "# Output embeddings to docVectors.json file\n",
    "with open(\"./sk_Vectors1.json\", \"w\") as f:\n",
    "    json.dump(doc_with_vector_list, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create search index - DO THIS ONLY ONCE !!!\n",
    "Create your search index schema and vector search configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mydocs created\n"
     ]
    }
   ],
   "source": [
    "# Create a search index\n",
    "# Note: You must create Cognitive Search resource and get the endpoint and key in advance\n",
    "index_client = SearchIndexClient(endpoint=service_endpoint, credential=credential)\n",
    "\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchableField(name=\"title\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"category\", type=SearchFieldDataType.String,\n",
    "                    filterable=True),\n",
    "    SearchField(name=\"titleVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\"),\n",
    "    SearchField(name=\"contentVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\"),\n",
    "]\n",
    "\n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(\n",
    "            name=\"myHnsw\"\n",
    "        )\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"myHnswProfile\",\n",
    "            algorithm_configuration_name=\"myHnsw\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"title\"),\n",
    "        keywords_fields=[SemanticField(field_name=\"category\")],\n",
    "        content_fields=[SemanticField(field_name=\"content\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the semantic settings with the configuration\n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name=index_name, fields=fields,\n",
    "                    vector_search=vector_search, semantic_search=semantic_search)\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f' {result.name} created')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert text and embeddings into vector store - DO THIS ONLY ONCE !!\n",
    "Add texts and metadata from the JSON data to the vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 187 documents\n"
     ]
    }
   ],
   "source": [
    "# Upload documents to the index\n",
    "with open('./sk_Vectors1.json', 'r') as file:\n",
    "    documents = json.load(file)\n",
    "search_client = SearchClient(endpoint=service_endpoint, index_name=index_name, credential=credential)\n",
    "result = search_client.upload_documents(documents)\n",
    "print(f\"Uploaded {len(documents)} documents\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a vector similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Semantic Kernel\n",
      "Score: 0.8932474\n",
      "Content: Tell us about y our PDF experience.\n",
      "What is Semantic Kernel?\n",
      "Article •07/11/2023\n",
      "Semantic K ernel is an open-source SDK that lets you easily combine AI services like\n",
      "OpenAI , Azure OpenAI , and Hugging F ace  with conventional programming\n",
      "languages like C# and Python. By doing so, you can create AI apps that combine the\n",
      "best of both worlds.\n",
      "During K evin Scott's talk The era of the AI Copilot , he showed how Microsoft powers its\n",
      "Copilot system  with a stack of AI models and plugins. At the center of this stack is an AI\n",
      "orchestration layer that allows us to combine AI models and plugins together to create\n",
      "brand new experiences for users.\n",
      "Semantic Kernel is at the center of the copilot\n",
      "stack\n",
      "Category: None\n",
      "\n",
      "Title: Semantic Kernel\n",
      "Score: 0.8851806\n",
      "Content: Additional learning for Semantic Kernel\n",
      "Article •07/11/2023\n",
      "Want to learn more about Semantic K ernel? Check out these in-depth tutorials and\n",
      "videos. W e will add more content over time from our team and community, so check\n",
      "back often!\n",
      "Cook with Semantic Kernel\n",
      "Learn how to supercharge your problem-solving creativity with Semantic K ernel running\n",
      "on your own machine just like your own “Easy Bake Oven.” W e’ll use plenty of cooking\n",
      "analogies to land the core ideas of LLM AI running on Semantic K ernel so be prepared\n",
      "to get hungry!\n",
      " \n",
      "Kernel syntax examplesStart the tut orial\n",
      "Category: None\n",
      "\n",
      "Title: Semantic Kernel\n",
      "Score: 0.88440174\n",
      "Content: Visual Code Studio Semantic Kernel\n",
      "Extension\n",
      "Article •05/23/2023\n",
      "The Semantic K ernel T ools help developers to write semantic functions for Semantic\n",
      "Kernel .\n",
      "With the Semantic K ernel T ools, you can easily create new semantic functions and test\n",
      "them without needing to write any code. Behind the scenes, the tools use the Semantic\n",
      "Kernel SDK so you can easily transition from using the tools to integrating your semantic\n",
      "functions into your own code.\n",
      "In the following image you can see how a user can easily view all of their semantic\n",
      "functions, edit them, and run them from within Visual S tudio Code using any of the\n",
      "supported AI endpoints.\n",
      "７ Note\n",
      "Skills are currently being renamed to plugins. This article has been updated to\n",
      "reflect the latest terminology, but some images and code samples may still refer to\n",
      "skills.\n",
      "These tools simplify Semantic Kernel\n",
      "development\n",
      "Category: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.models import VectorizedQuery\n",
    "\n",
    "# Pure Vector Search\n",
    "query = \"what is semantic kernel?\"  \n",
    "  \n",
    "embedding = client.embeddings.create(input=query, model=azure_openai_embedding_deployment).data[0].embedding\n",
    "vector_query = VectorizedQuery(vector=embedding, k_nearest_neighbors=3, fields=\"contentVector\")\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['content']}\")  \n",
    "    print(f\"Category: {result['category']}\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Semantic Kernel\n",
      "Score: 0.87037426\n",
      "Content: To simplify the creation of AI apps, open source projects like LangChain  have\n",
      "emerged. Semantic K ernel is Microsoft's contribution to this space and is designed to\n",
      "support enterprise app developers who want to integrate AI into their existing apps.\n",
      "By using multiple AI models, plugins, and memory all together within Semantic K ernel,\n",
      "you can create sophisticated pipelines that allow AI to automate complex tasks for users.\n",
      "For example, with Semantic K ernel, you could create a pipeline that helps a user send an\n",
      "email to their marketing team. With memory , you could retrieve information about the\n",
      "project and then use planner  to autogenerate the remaining steps using available\n",
      "plugins (e.g., ground the user's ask with Microsoft Graph data, generate a response with\n",
      "GPT-4, and send the email). Finally, you can display a success message back to your user\n",
      "in your app using a custom plugin.\n",
      "Step Component Descr iption\n",
      "1 Ask It starts with a goal being sent to Semantic K ernel by either a user or\n",
      "developer.\n",
      "2 Kernel The kernel  orchestrates a user's ask. T o do so, the kernel runs a pipeline /\n",
      "chain  that is defined by a developer. While the chain is run, a common\n",
      "context is provided by the kernel so data can be shared between functions.\n",
      "2.1 Memories With a specialized plugin, a developer can recall and store context in\n",
      "vector databases. This allows developers to simulate memory  within their\n",
      "AI apps.\n",
      "2.2 Planner Developers can ask Semantic K ernel to auto create chains to address novel\n",
      "needs for a user. Planner  achieves this by mixing-and-matching plugins\n",
      "Seeing AI orchestration with Semantic Kernel\n",
      "Title: Semantic Kernel\n",
      "Score: 0.8700594\n",
      "Content: This article only scratches the surface of what you can do with the kernel. T o learn more\n",
      "about additional features, check out the following articles.\n",
      "Your go al Next st ep\n",
      "Learn what plugins are and what they can do Understand AI plugins\n",
      "Create more advanced pipelines with Semantic K ernel Chaining functions together\n",
      "Automatically creating pipelines with Planner Auto create plans with planner\n",
      "Simulating memory within Semantic K ernel Give you AI memories\n",
      "Under standing plugins\n"
     ]
    }
   ],
   "source": [
    "query = \"semantic kernel planner and kernel\"\n",
    "\n",
    "embedding = client.embeddings.create(input=query, model=azure_openai_embedding_deployment).data[0].embedding\n",
    "vector_query = VectorizedQuery(vector=embedding, k_nearest_neighbors=2, fields=\"contentVector\")\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=None,\n",
    "    vector_queries=[vector_query], \n",
    "    select=[\"title\", \"content\"],\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform an Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Semantic Kernel\n",
      "Score: 0.03306011110544205\n",
      "Content: To simplify the creation of AI apps, open source projects like LangChain  have\n",
      "emerged. Semantic K ernel is Microsoft's contribution to this space and is designed to\n",
      "support enterprise app developers who want to integrate AI into their existing apps.\n",
      "By using multiple AI models, plugins, and memory all together within Semantic K ernel,\n",
      "you can create sophisticated pipelines that allow AI to automate complex tasks for users.\n",
      "For example, with Semantic K ernel, you could create a pipeline that helps a user send an\n",
      "email to their marketing team. With memory , you could retrieve information about the\n",
      "project and then use planner  to autogenerate the remaining steps using available\n",
      "plugins (e.g., ground the user's ask with Microsoft Graph data, generate a response with\n",
      "GPT-4, and send the email). Finally, you can display a success message back to your user\n",
      "in your app using a custom plugin.\n",
      "Step Component Descr iption\n",
      "1 Ask It starts with a goal being sent to Semantic K ernel by either a user or\n",
      "developer.\n",
      "2 Kernel The kernel  orchestrates a user's ask. T o do so, the kernel runs a pipeline /\n",
      "chain  that is defined by a developer. While the chain is run, a common\n",
      "context is provided by the kernel so data can be shared between functions.\n",
      "2.1 Memories With a specialized plugin, a developer can recall and store context in\n",
      "vector databases. This allows developers to simulate memory  within their\n",
      "AI apps.\n",
      "2.2 Planner Developers can ask Semantic K ernel to auto create chains to address novel\n",
      "needs for a user. Planner  achieves this by mixing-and-matching plugins\n",
      "Seeing AI orchestration with Semantic Kernel\n",
      "Category: None\n",
      "\n",
      "Title: Semantic Kernel\n",
      "Score: 0.032258063554763794\n",
      "Content: Responsible AI and Semantic Kernel\n",
      "Article •05/23/2023\n",
      "An AI system includes not only the technology, but also the people who will use it, the\n",
      "people who will be affected by it, and the environment in which it is deployed. Creating\n",
      "a system that is fit for its intended purpose requires an understanding of how the\n",
      "technology works, what its capabilities and limitations are, and how to achieve the best\n",
      "performance. Microsoft’s T ransparency Notes are intended to help you understand how\n",
      "our AI technology works, the choices system owners can make that influence system\n",
      "performance and behavior, and the importance of thinking about the whole system,\n",
      "including the technology, the people, and the environment. Y ou can use T ransparency\n",
      "Notes when developing or deploying your own system, or share them with the people\n",
      "who will use or be affected by your system.\n",
      "Microsoft’s T ransparency Notes are part of a broader effort at Microsoft to put our AI\n",
      "Principles into practice. T o find out more, see the Microsoft AI principles .\n",
      "Semantic K ernel (SK) is a lightweight SDK that lets you easily mix conventional\n",
      "programming languages with the latest in Large Language Model (LLM) AI \"prompts\"\n",
      "with templating, chaining, and planning capabilities out-of-the-box.\n",
      "Semantic K ernel (SK) builds upon the following five concepts:\n",
      "Concept Shor t Descr iption\n",
      "Kernel The kernel orchestrates a user's ASK expressed as a goal\n",
      "Planner Planner breaks it down into steps based upon resources that are available\n",
      "Plugins Plugins are customizable resources built from LLM AI prompts and native codeWhat is a Transparency Note?\n",
      "Introduction to Semantic Kernel\n",
      "The basics of Semantic Kernel\n",
      "Category: None\n",
      "\n",
      "Title: Semantic Kernel\n",
      "Score: 0.03067915514111519\n",
      "Content: This article only scratches the surface of what you can do with the kernel. T o learn more\n",
      "about additional features, check out the following articles.\n",
      "Your go al Next st ep\n",
      "Learn what plugins are and what they can do Understand AI plugins\n",
      "Create more advanced pipelines with Semantic K ernel Chaining functions together\n",
      "Automatically creating pipelines with Planner Auto create plans with planner\n",
      "Simulating memory within Semantic K ernel Give you AI memories\n",
      "Under standing plugins\n",
      "Category: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hybrid Search\n",
    "query = \"semantic kernel planner and kernel\"  \n",
    "  \n",
    "embedding = client.embeddings.create(input=query, model=azure_openai_embedding_deployment).data[0].embedding\n",
    "vector_query = VectorizedQuery(vector=embedding, k_nearest_neighbors=3, fields=\"contentVector\")\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=query,  \n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    "    top=3\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['content']}\")  \n",
    "    print(f\"Category: {result['category']}\\n\")  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a Semantic Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.models import QueryType, QueryCaptionType, QueryAnswerType\n",
    "# Semantic Hybrid Search\n",
    "query = \"semantic kernel planner and kernel\"\n",
    "\n",
    "embedding = client.embeddings.create(input=query, model=azure_openai_embedding_deployment).data[0].embedding\n",
    "vector_query = VectorizedQuery(vector=embedding, k_nearest_neighbors=3, fields=\"contentVector\")\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=query,\n",
    "    vector_queries=[vector_query], \n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    "    query_type=QueryType.SEMANTIC, semantic_configuration_name='my-semantic-config', query_caption=QueryCaptionType.EXTRACTIVE, query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "    top=3\n",
    ")\n",
    "\n",
    "semantic_answers = results.get_answers()\n",
    "for answer in semantic_answers:\n",
    "    if answer.highlights:\n",
    "        print(f\"Semantic Answer: {answer.highlights}\")\n",
    "    else:\n",
    "        print(f\"Semantic Answer: {answer.text}\")\n",
    "    print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Reranker Score: {result['@search.reranker_score']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "    print(f\"Category: {result['category']}\")\n",
    "\n",
    "    captions = result[\"@search.captions\"]\n",
    "    if captions:\n",
    "        caption = captions[0]\n",
    "        if caption.highlights:\n",
    "            print(f\"Caption: {caption.highlights}\\n\")\n",
    "        else:\n",
    "            print(f\"Caption: {caption.text}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
