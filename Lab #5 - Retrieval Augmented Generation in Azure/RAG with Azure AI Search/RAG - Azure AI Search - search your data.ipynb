{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG with Azure AI search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "\n",
    "# Configure environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.models import Vector\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    SearchIndex,\n",
    "    SemanticConfiguration,\n",
    "    PrioritizedFields,\n",
    "    SemanticField,\n",
    "    SearchField,\n",
    "    SemanticSettings,\n",
    "    VectorSearch,\n",
    "    VectorSearchAlgorithmConfiguration,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "# Configure environment variables\n",
    "service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\")\n",
    "key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "\n",
    "OPENAI_GPT35_DEPLOYMENT_NAME = os.getenv(\"OPENAI_GPT35_DEPLOYMENT_NAME\")\n",
    "OPENAI_GPT4_DEPLOYMENT_NAME = os.getenv(\"OPENAI_GPT4_DEPLOYMENT_NAME\")\n",
    "OPENAI_GPT4V_DEPLOYMENT_NAME = os.getenv(\"OPENAI_GPT4V_DEPLOYMENT_NAME\")\n",
    "OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\"OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "OPENAI_DALLE_DEPLOYMENT_NAME = os.getenv(\"OPENAI_DALLE_DEPLOYMENT_NAME\")\n",
    "\n",
    "OPENAI_DEPLOYMENT_ENDPOINT = os.getenv(\"OPENAI_DEPLOYMENT_ENDPOINT\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Configure OpenAI API\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = OPENAI_DEPLOYMENT_ENDPOINT, \n",
    "  api_key=OPENAI_API_KEY,  \n",
    "  api_version=\"2023-05-15\"\n",
    ")\n",
    "credential = AzureKeyCredential(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read your data, generate OpenAI embeddings and export to a format to insert your Azure Cognitive Search index:\n",
    "embeddingmodel = AzureOpenAIEmbeddings(\n",
    "    deployment=OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME,\n",
    "    model=OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME,\n",
    "    azure_endpoint=OPENAI_DEPLOYMENT_ENDPOINT,\n",
    "    chunk_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Document Embeddings using OpenAI Ada Model\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "# Function to generate embeddings for title and content fields, also used for query embeddings\n",
    "def generate_embeddings(text):\n",
    "    embeddings = embeddingmodel.embed_query(text)\n",
    "    return embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a vector similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure Vector Search\n",
    "query = \"semantic kernel?\"\n",
    "\n",
    "search_client = SearchClient(service_endpoint, index_name=\"sk-cogsrch-vector-index-2\", credential=credential)\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=None,\n",
    "    vector=generate_embeddings(query),\n",
    "    top_k=3,\n",
    "    vector_fields=\"contentVector\",\n",
    "    select=[\"title\", \"content\"],\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"semantic kernel planner and kernel\"\n",
    "\n",
    "search_client = SearchClient(\n",
    "    service_endpoint, index_name=\"sk-cogsrch-vector-index-2\", credential=credential)\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=None,\n",
    "    vector=generate_embeddings(query), top_k=3,\n",
    "    vector_fields=\"contentVector\",\n",
    "    select=[\"title\", \"content\"],\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure Vector Search multi-lingual\n",
    "query = \"Planificador sem√°ntico del kernel y kernel\"\n",
    "\n",
    "search_client = SearchClient(\n",
    "    service_endpoint, index_name=\"sk-cogsrch-vector-index-2\", credential=credential)\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=None,\n",
    "    vector=generate_embeddings(query), top_k=3,\n",
    "    vector_fields=\"contentVector\",\n",
    "    select=[\"title\", \"content\"],\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Cross-Field Vector Search with a filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure Vector Search with Filter\n",
    "query = \"programming languages supported by semantic kernel\"\n",
    "\n",
    "search_client = SearchClient(service_endpoint, index_name=\"sk-cogsrch-vector-index-2\", credential=credential)\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=None,\n",
    "    vector=generate_embeddings(query), top_k=3,\n",
    "    vector_fields=\"titleVector, contentVector\",\n",
    "    filter=\"title eq 'Semantic Kernel'\",\n",
    "    select=[\"title\", \"content\"] #searching on two fields title and content\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform an Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Search\n",
    "query = \"semantic kernel planner and kernel\"\n",
    "\n",
    "search_client = SearchClient(service_endpoint, index_name=\"sk-cogsrch-vector-index-2\", credential=credential)\n",
    "\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=query,\n",
    "    vector=generate_embeddings(query), top_k=3,\n",
    "    vector_fields=\"contentVector\",\n",
    "    filter=\"title eq 'Semantic Kernel'\",\n",
    "    select=[\"title\", \"content\",],\n",
    "    top=3\n",
    ")\n",
    "\n",
    "print(type(results))\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a Semantic Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic Hybrid Search\n",
    "query = \"semantic kernel planner and kernel\"\n",
    "\n",
    "search_client = SearchClient(service_endpoint, index_name=\"sk-cogsrch-vector-index-2\", credential=credential)\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=query,\n",
    "    vector=generate_embeddings(query), top_k=3,\n",
    "    vector_fields=\"contentVector\",\n",
    "    select=[\"title\", \"content\"],\n",
    "    query_type=\"semantic\", query_language=\"en-us\", semantic_configuration_name='sk-semantic-config', query_caption=\"extractive\", query_answer=\"extractive\",\n",
    "    top=3\n",
    ")\n",
    "\n",
    "semantic_answers = results.get_answers()\n",
    "for answer in semantic_answers:\n",
    "    if answer.highlights:\n",
    "        print(f\"Semantic Answer: {answer.highlights}\")\n",
    "    else:\n",
    "        print(f\"Semantic Answer: {answer.text}\")\n",
    "    print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "\n",
    "    captions = result[\"@search.captions\"]\n",
    "    if captions:\n",
    "        caption = captions[0]\n",
    "        if caption.highlights:\n",
    "            print(f\"Caption: {caption.highlights}\\n\")\n",
    "        else:\n",
    "            print(f\"Caption: {caption.text}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
