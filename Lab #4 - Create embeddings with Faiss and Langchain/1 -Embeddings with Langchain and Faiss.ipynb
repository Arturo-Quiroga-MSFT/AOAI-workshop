{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Environment variables from .env file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_DEPLOYMENT_ENDPOINT = os.getenv(\"OPENAI_DEPLOYMENT_ENDPOINT\")\n",
    "OPENAI_DEPLOYMENT_NAME = os.getenv(\"OPENAI_DEPLOYMENT_NAME\")\n",
    "OPENAI_MODEL_NAME = os.getenv(\"OPENAI_MODEL_NAME\")\n",
    "OPENAI_DEPLOYMENT_VERSION = os.getenv(\"OPENAI_DEPLOYMENT_VERSION\")\n",
    "\n",
    "OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\"OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "OPENAI_ADA_EMBEDDING_MODEL_NAME = os.getenv(\"OPENAI_ADA_EMBEDDING_MODEL_NAME\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = OPENAI_DEPLOYMENT_ENDPOINT, \n",
    "  api_key=OPENAI_API_KEY,  \n",
    "  api_version=\"2023-05-15\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dschlesinger\\code\\ongoing\\workshops\\AOAI-workshop\\.venv\\lib\\site-packages\\langchain\\embeddings\\azure_openai.py:101: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://aidemos-workshop.openai.azure.com/ to https://aidemos-workshop.openai.azure.com//openai.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dschlesinger\\code\\ongoing\\workshops\\AOAI-workshop\\.venv\\lib\\site-packages\\langchain\\embeddings\\azure_openai.py:108: UserWarning: As of openai>=1.0.0, if `deployment` (or alias `azure_deployment`) is specified then `openai_api_base` (or alias `base_url`) should not be. Instead use `deployment` (or alias `azure_deployment`) and `azure_endpoint`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dschlesinger\\code\\ongoing\\workshops\\AOAI-workshop\\.venv\\lib\\site-packages\\langchain\\embeddings\\azure_openai.py:116: UserWarning: As of openai>=1.0.0, if `openai_api_base` (or alias `base_url`) is specified it is expected to be of the form https://example-resource.azure.openai.com/openai/deployments/example-deployment. Updating https://aidemos-workshop.openai.azure.com/ to https://aidemos-workshop.openai.azure.com//openai.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    deployment=OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME,\n",
    "    model=OPENAI_ADA_EMBEDDING_MODEL_NAME,\n",
    "    openai_api_base=OPENAI_DEPLOYMENT_ENDPOINT,\n",
    "    openai_api_type=\"azure\",\n",
    "    chunk_size = 1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Run ONLY ONCE to create the embeddings - Split text into chunks** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages:  292\n"
     ]
    }
   ],
   "source": [
    "fileName = \"./data/fabric-data-engineering.pdf\"\n",
    "loader = PyPDFLoader(fileName)\n",
    "pages = loader.load_and_split()\n",
    "print(\"Number of pages: \", len(pages))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Run ONLY ONCE to create the embeddings - Create embeddings and save to FAISS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(documents=pages, embedding=embeddings)\n",
    "# save the FAISS index to disk\n",
    "db.save_local(\"./dbs/documentation/faiss_index\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Initialize LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AzureOpenAI.__init__() got an unexpected keyword argument 'deployment_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dschlesinger\\code\\ongoing\\workshops\\AOAI-workshop\\Lab #4 - Create embeddings with Faiss and Langchain\\1 -Embeddings with Langchain and Faiss.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dschlesinger/code/ongoing/workshops/AOAI-workshop/Lab%20%234%20-%20Create%20embeddings%20with%20Faiss%20and%20Langchain/1%20-Embeddings%20with%20Langchain%20and%20Faiss.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     llm \u001b[39m=\u001b[39m AzureOpenAI(deployment_name\u001b[39m=\u001b[39mdeployment_name,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dschlesinger/code/ongoing/workshops/AOAI-workshop/Lab%20%234%20-%20Create%20embeddings%20with%20Faiss%20and%20Langchain/1%20-Embeddings%20with%20Langchain%20and%20Faiss.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                       model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dschlesinger/code/ongoing/workshops/AOAI-workshop/Lab%20%234%20-%20Create%20embeddings%20with%20Faiss%20and%20Langchain/1%20-Embeddings%20with%20Langchain%20and%20Faiss.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                       openai_api_version\u001b[39m=\u001b[39mopenai_api_version,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dschlesinger/code/ongoing/workshops/AOAI-workshop/Lab%20%234%20-%20Create%20embeddings%20with%20Faiss%20and%20Langchain/1%20-Embeddings%20with%20Langchain%20and%20Faiss.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                       model_kwargs\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mstop\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39m<|im_end|>\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dschlesinger/code/ongoing/workshops/AOAI-workshop/Lab%20%234%20-%20Create%20embeddings%20with%20Faiss%20and%20Langchain/1%20-Embeddings%20with%20Langchain%20and%20Faiss.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                       )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dschlesinger/code/ongoing/workshops/AOAI-workshop/Lab%20%234%20-%20Create%20embeddings%20with%20Faiss%20and%20Langchain/1%20-Embeddings%20with%20Langchain%20and%20Faiss.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dschlesinger/code/ongoing/workshops/AOAI-workshop/Lab%20%234%20-%20Create%20embeddings%20with%20Faiss%20and%20Langchain/1%20-Embeddings%20with%20Langchain%20and%20Faiss.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m llm \u001b[39m=\u001b[39m init_llm()\n",
      "\u001b[1;32mc:\\Users\\dschlesinger\\code\\ongoing\\workshops\\AOAI-workshop\\Lab #4 - Create embeddings with Faiss and Langchain\\1 -Embeddings with Langchain and Faiss.ipynb Cell 10\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dschlesinger/code/ongoing/workshops/AOAI-workshop/Lab%20%234%20-%20Create%20embeddings%20with%20Faiss%20and%20Langchain/1%20-Embeddings%20with%20Langchain%20and%20Faiss.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minit_llm\u001b[39m(model\u001b[39m=\u001b[39mOPENAI_MODEL_NAME,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dschlesinger/code/ongoing/workshops/AOAI-workshop/Lab%20%234%20-%20Create%20embeddings%20with%20Faiss%20and%20Langchain/1%20-Embeddings%20with%20Langchain%20and%20Faiss.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m              deployment_name\u001b[39m=\u001b[39mOPENAI_DEPLOYMENT_NAME,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dschlesinger/code/ongoing/workshops/AOAI-workshop/Lab%20%234%20-%20Create%20embeddings%20with%20Faiss%20and%20Langchain/1%20-Embeddings%20with%20Langchain%20and%20Faiss.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m              openai_api_version\u001b[39m=\u001b[39mOPENAI_DEPLOYMENT_VERSION,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dschlesinger/code/ongoing/workshops/AOAI-workshop/Lab%20%234%20-%20Create%20embeddings%20with%20Faiss%20and%20Langchain/1%20-Embeddings%20with%20Langchain%20and%20Faiss.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m              top_p\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dschlesinger/code/ongoing/workshops/AOAI-workshop/Lab%20%234%20-%20Create%20embeddings%20with%20Faiss%20and%20Langchain/1%20-Embeddings%20with%20Langchain%20and%20Faiss.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m              ):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/dschlesinger/code/ongoing/workshops/AOAI-workshop/Lab%20%234%20-%20Create%20embeddings%20with%20Faiss%20and%20Langchain/1%20-Embeddings%20with%20Langchain%20and%20Faiss.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     llm \u001b[39m=\u001b[39m AzureOpenAI(deployment_name\u001b[39m=\u001b[39;49mdeployment_name,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dschlesinger/code/ongoing/workshops/AOAI-workshop/Lab%20%234%20-%20Create%20embeddings%20with%20Faiss%20and%20Langchain/1%20-Embeddings%20with%20Langchain%20and%20Faiss.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                       model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dschlesinger/code/ongoing/workshops/AOAI-workshop/Lab%20%234%20-%20Create%20embeddings%20with%20Faiss%20and%20Langchain/1%20-Embeddings%20with%20Langchain%20and%20Faiss.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                       openai_api_version\u001b[39m=\u001b[39;49mopenai_api_version,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dschlesinger/code/ongoing/workshops/AOAI-workshop/Lab%20%234%20-%20Create%20embeddings%20with%20Faiss%20and%20Langchain/1%20-Embeddings%20with%20Langchain%20and%20Faiss.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                       base_url\u001b[39m=\u001b[39;49mOPENAI_DEPLOYMENT_ENDPOINT,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dschlesinger/code/ongoing/workshops/AOAI-workshop/Lab%20%234%20-%20Create%20embeddings%20with%20Faiss%20and%20Langchain/1%20-Embeddings%20with%20Langchain%20and%20Faiss.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m                       temperature\u001b[39m=\u001b[39;49mtemperature,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dschlesinger/code/ongoing/workshops/AOAI-workshop/Lab%20%234%20-%20Create%20embeddings%20with%20Faiss%20and%20Langchain/1%20-Embeddings%20with%20Langchain%20and%20Faiss.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                       max_tokens\u001b[39m=\u001b[39;49mmax_tokens,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dschlesinger/code/ongoing/workshops/AOAI-workshop/Lab%20%234%20-%20Create%20embeddings%20with%20Faiss%20and%20Langchain/1%20-Embeddings%20with%20Langchain%20and%20Faiss.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                       top_p\u001b[39m=\u001b[39;49mtop_p,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dschlesinger/code/ongoing/workshops/AOAI-workshop/Lab%20%234%20-%20Create%20embeddings%20with%20Faiss%20and%20Langchain/1%20-Embeddings%20with%20Langchain%20and%20Faiss.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                       model_kwargs\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mstop\u001b[39;49m\u001b[39m\"\u001b[39;49m: [\u001b[39m\"\u001b[39;49m\u001b[39m<|im_end|>\u001b[39;49m\u001b[39m\"\u001b[39;49m]}\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dschlesinger/code/ongoing/workshops/AOAI-workshop/Lab%20%234%20-%20Create%20embeddings%20with%20Faiss%20and%20Langchain/1%20-Embeddings%20with%20Langchain%20and%20Faiss.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                       )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dschlesinger/code/ongoing/workshops/AOAI-workshop/Lab%20%234%20-%20Create%20embeddings%20with%20Faiss%20and%20Langchain/1%20-Embeddings%20with%20Langchain%20and%20Faiss.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\n",
      "\u001b[1;31mTypeError\u001b[0m: AzureOpenAI.__init__() got an unexpected keyword argument 'deployment_name'"
     ]
    }
   ],
   "source": [
    "def init_llm(model=OPENAI_MODEL_NAME,\n",
    "             deployment_name=OPENAI_DEPLOYMENT_NAME,\n",
    "             openai_api_version=OPENAI_DEPLOYMENT_VERSION,\n",
    "             temperature=0,\n",
    "             max_tokens=400,\n",
    "             top_p=1,\n",
    "             ):\n",
    "\n",
    "    llm = AzureOpenAI(deployment_name=deployment_name,\n",
    "                      model=model,\n",
    "                      openai_api_version=openai_api_version,\n",
    "                      base_url=OPENAI_DEPLOYMENT_ENDPOINT,\n",
    "                      temperature=temperature,\n",
    "                      max_tokens=max_tokens,\n",
    "                      top_p=top_p,\n",
    "                      model_kwargs={\"stop\": [\"<|im_end|>\"]}\n",
    "                      )\n",
    "    return llm\n",
    "llm = init_llm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Initialize retrieval API WITHOUT your data - get wrong answers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Power BI is a cloud-based business analytics service provided by Microsoft that allows you to connect to your data sources, visualize and share insights. While there's no hard and fast rule for how much data Power BI can handle, it's generally recommended to keep the data volume less than 1-2 GB. \n",
       "\n",
       "Handling 110 GB of data with Power BI would not be the best idea as it could lead to slow response times and poor performance. A better approach would be to use other options available for such data volumes like Azure Data Factory, SSIS, or Databricks. These options provide cloud-based data integration, transformation, and migration capabilities that can handle large data volumes with ease. You could also consider using a dedicated data warehouse solution like Azure Synapse Analytics or AWS Redshift to store and analyze large volumes of data efficiently. These solutions are optimized for analytics and can handle large volumes of data with ease."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, JSON, Markdown\n",
    "\n",
    "answer = llm(\"How do I choose between a lakehouse and a data warehouse in Microsoft Fabric? \")\n",
    "# prepare prompt\n",
    "messages = [{\"role\": \"system\", \"content\": \"You are a HELPFUL assistant answering users questions. Answer in a clear and concise manner.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Can I use PowerBI datamart for 110 GB data volume? Explain which other options are available for data volumes of 110 GB?\"}]\n",
    "\n",
    "\n",
    "answer = openai.ChatCompletion.create(engine=OPENAI_DEPLOYMENT_NAME,\n",
    "\n",
    "                                      messages=messages,)\n",
    "display(HTML(answer.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Initialize retrieval API WITH your data - get the right answers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the vector store to memory\n",
    "vectorStore = FAISS.load_local(\"./dbs/documentation/faiss_index\", embeddings)\n",
    "retriever = vectorStore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})  # returns 2 most similar vectors/documents\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Ask questions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Can I use PowerBI datamart for 110 GB data volume? Explain which other options are available for data volumes of 110 GB?',\n",
       " 'result': ' No, PowerBI datamart is only suitable for data volumes up to 100 GB. For data volumes of 110 GB, you can use a data warehouse or a lakehouse in Microsoft Fabric. \\n\\nData warehouse is suitable for structured data, and is ideal for SQL engineers and data warehouse developers. It is organized by databases, schemas, and tables, and read operations can be performed using Spark and T-SQL. Write operations can be performed using T-SQL.\\n\\nLakehouse is suitable for unstructured, semi-structured, and structured data, and is ideal for data engineers and data scientists. It is organized by folders and files, databases, and tables, and read operations can be performed using Spark, T-SQL, and Power BI. Write operations can be performed using Spark (Scala, PySpark, Spark SQL, R) and T-SQL. \\n\\nBoth data warehouse and lakehouse can handle unlimited data volume. \\n\\nNote that Microsoft Fabric is currently in PREVIEW, and the information provided may be subject to change.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa({\"query\": \"Can I use PowerBI datamart for 110 GB data volume? Explain which other options are available for data volumes of 110 GB?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What are the steps to load a CSV file to a delta table in Microsoft Fabric?',\n",
       " 'result': ' The steps to load a CSV file to a delta table in Microsoft Fabric are:\\n1. Select Synapse Data Engineering experience in Microsoft Fabric.\\n2. Make sure you are in the desired workspace or select/create one.\\n3. Select the Lakehouse icon under the New section in the main image.\\n4. Upload the CSV file to the Lakehouse.\\n5. Convert the file to a Delta table. \\n6. Generate a Dataset and create a Power BI report.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa({\"query\": \"What are the steps to load a CSV file to a delta table in Microsoft Fabric?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
